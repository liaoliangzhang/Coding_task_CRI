---
title: "Tech 5, Main Analyses"
output: html_notebook
---

This package is needed
http://www.alexlishinski.com/post/2018-04-13-lavaanplot0.5/

   

```{r setup, include=FALSE, warning=F}
rm(list = ls())
library(pacman)


pacman::p_load("ggplot2","dplyr","readr","plotscale","lattice","tidyr","readxl","mlogit","jtools","sjPlot","sjmisc","sjlabelled","knitr","kableExtra","lavaan","reshape2","semPlot","lavaanPlot","leaps","lme4","multilevelTools","rvest")

# add in variance estimates (more than 2-digits)
# disable scientific notation
options(scipen = 999)

# Column no missing function
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
```

## Data Prep

These datasets were worked up from the file 01_CRI_Data_Prep.Rmd. 

cri = numerical values
cri_str = string values
cri_team = team-level data (by conclusion)
cri_team_combine = team-level data parsed by type of test variable (stock and flow)
cri_indiv = participant-level data from our survey, identifying characteristics redacted

### Load Data

```{r load, warning=F,message=F}
cri <- read.csv(file = "data/cri.csv", header = T)
cri_str <- read.csv(file = "data/cri_str.csv", header = T)
cri_team <- read.csv(file = "data/cri_team_combine.csv", header = T)
cri_indiv <- read.csv(file = "data/cri_indv.csv", header = T)

# setup multilevel dataset

cri_ml <- select(cri,u_teamid, id, u_delibtreatmentgroup1, AME:main_IV_source, main_IV_measurement:package, countries, Jobs:anynonlin,AME_Z,lower_Z,upper_Z,Hsup,Hrej,Hno,AME_sup_p05:AME_ns_p05,u_expgroup1,belief_strength:belief_ipred, HresultF)

# create a team ID variable to identify the independent tests by team. Again, 16 of 71 teams had independent conclusions - seeing stock v flow immigration measures as representative of independent tests of the hypothesis. Therefore, we have a team-test level that replaces the team level.

cri_ml$team <- cri_ml %>% group_indices(u_teamid, HresultF)

cri_ml <- select(cri_ml, u_teamid, id, team, AME_Z, upper_Z, lower_Z, everything())

# remove team 0
cri_ml <- subset(cri_ml, u_teamid != 0)

```

### Within and Between Variables

```{r wandb}
cri_ml <- cri_ml %>%
  group_by(team) %>%
  mutate(AME_Z_b = mean(AME_Z, na.rm = T),
         AME_Z_w =AME_Z-AME_Z_b,
         jobs_b = mean(Jobs, na.rm = T),
         unemp_b = mean(Unemp, na.rm = T),
         incdiff_b = mean(IncDiff, na.rm = T),
         oldage_b = mean(OldAge, na.rm = T),
         house_b = mean(House, na.rm = T),
         health_b = mean(Health, na.rm = T),
         jobs_w = Jobs-jobs_b,
         unemp_w = Unemp-unemp_b,
         incdiff_w = IncDiff-incdiff_b,
         oldage_w = OldAge-oldage_b,
         house_w = House-house_b,
         health_w = Health-health_b,
         scale_b = mean(Scale, na.rm = T),
         scale_w = Scale-scale_b,
         un_emp_rate_ivC = ifelse(emplrate_ivC == 1 | unemprate_ivC == 1, 1, 0)) %>%
  ungroup()

# create factors for measurement
cri_ml <- cri_ml %>%
  mutate(main_IV_factor = as.factor(main_IV_measurement))

# team 27 is missing the survey variables
# as it is just one team, mean replacement should be fine
cri_ml <- cri_ml %>%
  mutate(stats_ipred = ifelse(is.na(stats_ipred), mean(stats_ipred, na.rm=T), stats_ipred),
         belief_ipred = ifelse(is.na(belief_ipred), mean(belief_ipred, na.rm =T), belief_ipred),
         topic_ipred = ifelse(is.na(topic_ipred), mean(topic_ipred, na.rm =T), topic_ipred))
```


# Regresssion Approach to Explaining Variance

## Explaining Average Marginal Effects

### Objective Conditions

Here we consider that the design of the CRI has an influence on the findings of the researchers. This includes the 6 variables to potentially use for the DV and the experimental conditions. We do not include the variable 'Scale' here because this required a conscious choice by the teams to deviate from the observed DVs that were provided.

We consider random assignment to the opaque or transparent replication group (variable = u_expgroup1) and the deliberation group (variable = u_delibtreatmentgroup1) as objectively imposed conditions (not a choice by the teams).

The problem we face is that there is only an average of roughly 13 models per team, and 87 teams. This means we start to lose the ability to explain variance. A degrees of freedom problem. Therefore, in this process we have to reduce complexity. 



```{r obj_mlms}
m00 <- lmer(AME_Z ~ (1 | team), data = cri_ml)
#m01a <- lmer(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + (1 | team), data = cri_ml)

# these variables do all the work, so we reduce complexity
m01 <- lmer(AME_Z ~ Jobs + IncDiff + House + (1 | team), data = cri_ml)
m02 <- lmer(AME_Z ~ Jobs + IncDiff + House + u_expgroup1 + u_delibtreatmentgroup1 + (1 | team), data = cri_ml)

m00v <- as.data.frame(VarCorr(m00))
m01v <- as.data.frame(VarCorr(m01))
m02v <- as.data.frame(VarCorr(m02))

m01vars <- "AME_Z ~ Jobs + IncDiff + House"

```

### Subjective Decisions

#### Measurement

The teams had several possibilities to measure the DV (or DVs) including linear, logit or multinomial. Also, immigration could be stock or flow and some teams elected for change in flow. A few teams used measures like refugee or non-western instead of simply foreign-born. These decisions are reflected here.

note that logit is the only one that seems to matter, surprisingly the 'type' of measure does not matter (foreign-born, non-western, refugee, etc.; although there are far fewer models that do not simply use foreign-born)

```{r subj_measurement_mlms}

m03 <- lmer(paste0(m01vars, "+ logit + ologit + lpm + mlogit + ols + (1 | team)"), data = cri_ml)

#note that Flow is the omitted category (ChangeFlow is too rare to make a good omitted category)

# m04 <- lmer(paste0(m01vars, "+ logit + ologit + lpm + mlogit + ols + Stock + Flow + main_IV_factor + (1 | team)"), data = cri_ml)

m04 <- lmer(paste0(m01vars, "+ logit + ols + Stock + ChangeFlow + (1 | team)"), data = cri_ml)

m03v <- as.data.frame(VarCorr(m03))
m04v <- as.data.frame(VarCorr(m04))

m04vars <- "+ logit + ols + Stock + ChangeFlow"

```


#### Data and Sample

```{r subj_datasamp_mlms, warning = F}

m05 <- lmer(paste0(m01vars, m04vars, "+ w1996 + w2006 + w2016 + w2006*w2016 + (1 | team)"), data = cri_ml)

# several interactions were tried here that seemed useful in the single-level equation, but they just wash out the results, many making the variance worse

m06 <- lmer(paste0(m01vars, m04vars, "+ w1996 + w2006 + w2016 + w2006*w2016 + orig13  + eeurope + allavailable +  (1 | team)"), data = cri_ml)

m05v <- as.data.frame(VarCorr(m05))
m06v <- as.data.frame(VarCorr(m06))


m06vars <- "+ w1996 + w2006 + w2016 + w2006*w2016 + orig13  + eeurope + allavailable"
```


#### Model Design

m07 estimator, mlm structure

main IVs in same model or not (this causes one team to get dropped so we don't use it, didn't add anything when added anyways)

m08 independent vars l2 selection

```{r subj_model_mlms}

m07 <- lmer(paste0(m01vars, m04vars, m06vars, " + twowayfe + level_cyear + mlm_fe + mlm_re  + (1 | team)"), data = cri_ml)
m08 <- lmer(paste0(m01vars, m04vars, m06vars, " + twowayfe + mlm_fe + level_cyear  + mlm_re  + gdp_ivC + anynonlin + (1 | team) "), data = cri_ml)
# tried ml_glm, w2016*twowayfe, bayes, un_emp_rate_ivC 

m07v <- as.data.frame(VarCorr(m07))
m08v <- as.data.frame(VarCorr(m08))

m07vars <- " + twowayfe + level_cyear + mlm_fe + mlm_re"
m08vars <- "+ twowayfe + mlm_fe + level_cyear  + mlm_re  + gdp_ivC + anynonlin"

# mlm_fe + mlm_re doesn't help
m07adj_vars <- " + twowayfe + level_cyear"
```


### Researcher Aspects

*belief_ipred* - Belief that Hypothesis is true (that immigration reduces support), team average of predicted factor scores
*pro_immigrant* - Support laws to better integrate immigrants, team average, single question
*topic_ipred* - Knowledge and experience with the topic of immigration and welfare state preferences, team average of predicted factor scores
*stats_ipred* - Knowledge and experience with quantiative statistical analysis, team average of predicted factor scores
*total_score* - Average score of each model from subjective voting amongst participants, each participant reviewed 3 to 4 models

Maximum variance explained

It becomes clear that models 7 and 8 are detrimental to the variance explained,
therefore the following results combine only with m06

Using the R^2 'hacking' tool we found some combinations of these variables that maximized r^2 (m11)

These probably need to be run independently, so that we see the reduction for each one.

```{r res_aspects_mlms}
m09 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ belief_ipred + (1 | team)"), data = cri_ml)
m10 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ pro_immigrant +  (1 | team)"), data = cri_ml) 

m11 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ topic_ipred + (1 | team)"), data = cri_ml) 

m12 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ stats_ipred + (1 | team)"), data = cri_ml) 

m13 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ total_score + (1 | team)"), data = cri_ml)

m14 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ pro_immigrant + stats_ipred + (1 | team)"), data = cri_ml) 
# even a cor of 0.19 is probably causing problems at the team-level with so few degrees of freedom
#> cor(cri_ml$pro_immigrant,cri_ml$stats_ipred, use = "complete.obs")
#[1] 0.1914521

# m15 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ pro_immigrant + stats_ipred + (1 | team)"), data = cri_ml) 

m09v <- as.data.frame(VarCorr(m09))
m10v <- as.data.frame(VarCorr(m10))
m11v <- as.data.frame(VarCorr(m11))
m12v <- as.data.frame(VarCorr(m12))
m13v <- as.data.frame(VarCorr(m13))
m14v <- as.data.frame(VarCorr(m14))
# m15v <- as.data.frame(VarCorr(m15))


```

### Combine All

```{r comb_tbl}
tab_model(m00,m01,m02,m04,m06,m07,m09,m10,m11,m12,m13, digits = 3, p.style = "stars", show.ci = F, file = "results/reg11.htm")

reg11 <- as.data.frame(read_html("results/reg11.htm") %>% html_table(fill=TRUE))

colnames(reg11) <- c("Effect", "m00","m01", "m02","m04", "m06","m07","m09","m10", "m11","m12","m13")


# Add residual variance by level to model (extracted from VarCorr calls)
# NOTE! This will not run properly if the number of variables changes above

reg11[28,1] <- "Residual Variance"
reg11[28,2:12] <- ""
reg11[29,1] <- "Team-Level"
reg11[29,2:12] <- round(as.numeric(c(m00v[1,4],m01v[1,4],m02v[1,4],m04v[1,4],
                    m06v[1,4],m07v[1,4],m09v[1,4],m10v[1,4],
                    m11v[1,4],m12v[1,4],m13v[1,4])),6)

reg11[30,1] <- "Model-Level"
reg11[30,2:12] <- round(as.numeric(c(m00v[nrow(m00v),4],m01v[nrow(m00v),4],m02v[nrow(m00v),4],
                    m04v[nrow(m00v),4],m06v[nrow(m00v),4],m07v[nrow(m00v),4],
                    m09v[nrow(m00v),4],m10v[nrow(m00v),4],m11v[nrow(m00v),4],
                    m12v[nrow(m00v),4],m13v[nrow(m00v),4])),6
                    )

# calculate var reduction by level

reg11[31,1] <- c("Total")

reg11[31,2:12] <- round(as.numeric(reg11[29,2:12]) + as.numeric(reg11[30,2:12]),6)

reg11[32,1] <- "Variance Explained"
reg11[32,2:12] <- ""

# capture p-value expression
p <- reg11[35,1]

reg11[33,1] <- "Team-Level"
reg11[34,1] <- "Model-Level"
reg11[35,1] <- "Total"

reg11[33,2:12] <- round(1 - (as.numeric(reg11[29,2:12]) / as.numeric(reg11[29,2])),6)
reg11[34,2:12] <- round(1 - (as.numeric(reg11[30,2:12]) / as.numeric(reg11[30,2])),6)
reg11[35,2:12] <- round(1 - (as.numeric(reg11[31,2:12]) / as.numeric(reg11[31,2])),6)

reg11[36,1] <- p
reg11[36,2:12] <- ""

kable_styling(kable(reg11))
```


```{r variance_explained_table}





var_table <- var_table %>%
  mutate(team_level = as.numeric(team_level),
         model_level = as.numeric(model_level),
         total = team_level + model_level)

var_table$team_var_reduc <- (var_table[2,2] - var_table$team_level)/var_table[2,2]
var_table$model_var_reduc <- (var_table[2,3] - var_table$model_level)/var_table[2,3]
var_table$total_var_reduc <- ((var_table[2,2] + var_table[2,3]) - (var_table$total)) / (var_table[2,2] + var_table[2,3])


tbl2  <- var_table
tbl2[2,5:7] <- tbl2[2,2:4]


tbl2 <- select(tbl2, model, team_var_reduc, model_var_reduc, total_var_reduc)

tbl2[1,2:4] <- c("Team-Levela (n=87)","Model-Levela (n=1,253)","Total")
tbl2[2:19,1] <- c("Observed Outcome Variance","","Objective Conditions","Structure of Materials Provided","Group Assignment","Researcher Decisions", "Measurement","Data and Sample","Model Specification","Researcher Attributes","Prior Belief in Hypothesis", "Pro-Immigration Attitude","Knowledge of Topic","Statistical Skills","Peer Model Ranking","","Unexplained Variance","aOf the 71 teams, 16 had independent tests and conclusions for stock and flow models leading to 87 team-level results. Of the 1,261 models submitted, 8 had convergence problems")






```






















#### Test IV Type - unweighted

These results do not take into account the varying number of models per team

```{r m1_ivsplit, include = TRUE, warning = F}

cri_stock <- subset(cri, cri$Stock == 1)
cri_flow <- subset(cri, cri$Flow == 1)

#Stock models
m1a_stock <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_stock)
m1b_stock <- lm(p ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_stock)
m1c_stock <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale + p, data = cri_stock)

#Flow models
m1a_flow <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_flow)
m1b_flow <- lm(p ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_flow)
m1c_flow <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale + p, data = cri_flow)

tab_model(m1a_stock,m1b_stock,m1c_stock,m1a_flow,m1b_flow,m1c_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))


```

#### Test IV Type - weighted

We abandon estimation of p-values here. They do not seem to be of substantive interest for us... yet.

Weighting does not improve explained variance.

```{r m1_weight, include = TRUE}

m1aw <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri, weight = (inv_weight/1)*112)
m1aw_stock <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_stock, weights = (inv_weight/1)*112)
m1aw_flow <- lm(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_flow, weights = (inv_weight/1)*112)


tab_model(m1aw,m1aw_stock,m1aw_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))


```

#### Pooled by Test Type

```{r m2_pooled_iv_type}

# Pooled by test variable, ref = change in flow

m2 <- lm(AME_Z ~ factor(main_IV_type), data = cri)

tab_model(m2, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))

```

#### Waves of Data Used

##### Model Specifications - testing universe of wave combinations

Results suggest that using a 2006*2016 interaction 'maximizes' explained variance at 0.008.It suggests leaving out the main effect for w2016, but this is substantively awkward, so we put it back in for the final regression in the next code chunk.

```{r wave_test}

# the use of 1985 and 1990 is quite rare so we focus on the latter three waves as potential interactions
m_wave <-
    regsubsets(AME_Z ~ w1985 + w1990 + w1996 + w2006 + w2016 + w1996*w2006 + w1996*w2016 + w1996*w2006*w2016 + w2006*w2016,
               data = cri,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

plot(m_wave, scale = "adjr2", main = "Adjusted R^2")
```

##### Sample Selection Waves

```{r m3}
m3 <- lm(AME_Z ~ w2006 + w2016 + w2006*w2016, data = cri)
m3_stock <- lm(AME_Z ~ w2006 + w2016 + w2006*w2016, data = cri_stock)
m3_flow <- lm(AME_Z ~ w1996 + w2006 + w2016 + w2006*w2016, data = cri_flow)

tab_model(m3, m3_stock, m3_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))
```


#### Sample Selection Related IVs

##### Universe approach

After running this, it is not even worth modeling. We can only get up to Adj r^2 around 0.01.

```{r sample_test}

# we do not interact all variables because they are mostly mutually exclusive 
m_sample <-
    regsubsets(AME_Z ~ w2006 + w2016 + w2006*w2016 + orig13 + orig17 + eeurope + allavailable + w2016*orig13 + w2016*orig17 + w2016*eeurope + w2016*allavailable + w2006*w2016*orig13 + w2006*w2016*orig17 + w2006*w2016*eeurope + w2006*w2016*allavailable + w2006*w2016*orig13 + w2006*orig13 + w2006*orig17 + w2006*eeurope + w2006*allavailable,
               data = cri,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

plot(m_sample, scale = "adjr2", main = "Adjusted R^2")
```

##### Sample selection

orig13
orig17, dropped, see above
eeurope
allavailable



```{r m4}
m4 <- lm(AME_Z ~ orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable, data = cri)
m4_stock <- lm(AME_Z ~ orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable, data = cri_stock)
m4_flow <- lm(AME_Z ~ orig13  + eeurope + allavailable + + w1996 + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable, data = cri_flow)

tab_model(m4, m4_stock, m4_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))

```


### Team Qualities




#### Correlations

```{r rq_corr}
cor_rq <- select(cri, AME_Z, Hsup, AME_sup_p05, belief_ipred, pro_immigrant, topic_ipred, stats_ipred, total_score)
# cor_rq <- completeFun(cor_rq, c("AME_Z", "belief_ipred"))
# cor_rq <- as.data.frame(cor_rq)
cor_rqa <- as.data.frame(round(cor(cor_rq, use = "pairwise.complete.obs"), 3))

# Start to build main findings table
cor_rqa <- as.data.frame(cor_rqa[4:8,1:3])
cor_rqa2 <- round(100*(cor_rqa^2), 3)

# Stock and Flow only
cor_rq_stock <- select(cri_stock, AME_Z, belief_ipred, pro_immigrant, topic_ipred, stats_ipred, total_score)
cor_rqa_stock <- as.data.frame(round(cor(cor_rq_stock, use = "pairwise.complete.obs"), 3))

cor_rqa_stock <- as.data.frame(cor_rqa_stock[2:6,1])
cor_rqa2_stock <- round(100*(cor_rqa_stock^2), 3)

cor_rq_flow <- select(cri_flow, AME_Z, belief_ipred, pro_immigrant, topic_ipred, stats_ipred, total_score)
cor_rqa_flow <- as.data.frame(round(cor(cor_rq_flow, use = "pairwise.complete.obs"), 3))

cor_rqa_flow <- as.data.frame(cor_rqa_flow[2:6,1])
cor_rqa2_flow <- round(100*(cor_rqa_flow^2), 3)

# bind all together

cor_rqa21 <- as.data.frame(cor_rqa2[,1])
cor_rqa22 <- as.data.frame(cor_rqa2[,2:3])
cor_rq_final <- bind_cols(cor_rqa21, cor_rqa2_stock, cor_rqa2_flow, cor_rqa22)

rm(cor_rq, cor_rq_flow, cor_rq_stock, cor_rqa, cor_rqa_flow, cor_rqa_stock, cor_rqa2, cor_rqa2_flow, cor_rqa2_stock)
```


#### Universe Approach

```{r qs_test}

# we do not interact all variables because they are mostly mutually exclusive 
m_qs <-
    regsubsets(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*pro_immigrant + belief_ipred*topic_ipred + belief_ipred*stats_ipred + belief_ipred*total_score + pro_immigrant*topic_ipred + pro_immigrant*stats_ipred + pro_immigrant*total_score + topic_ipred*stats_ipred + topic_ipred*total_score + stats_ipred*total_score,
               data = cri,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

plot(m_qs, scale = "adjr2", main = "Adjusted R^2")
```

```{r m20}
m20 <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred, data = cri)
m20_stock <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred, data = cri_stock)
m20_flow <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred, data = cri_flow)

tab_model(m20, m20_stock, m20_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))

```


### All Aspects Combined


```{r m30}
m30 <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred + orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable + Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri)

m30_stock <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred + orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable + Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_stock)

m30_flow <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred + orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable + Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_flow)

tab_model(m30, m30_stock, m30_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))
```


### All Aspects Combined Weighted


```{r m30w}
m30_w <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred + orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable + Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri, weights = (inv_weight/1)*112)

m30_stock_w <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred + orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable + Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_stock, weights = (inv_weight/1)*112)

m30_flow_w <- lm(AME_Z ~ belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score + belief_ipred*topic_ipred + belief_ipred*stats_ipred + pro_immigrant*stats_ipred + topic_ipred*stats_ipred + orig13  + eeurope + allavailable + w2006 + w2016 + w2006*w2016 + w2016*eeurope + w2016*allavailable + Jobs + Unemp + IncDiff + OldAge + House + Health + Scale, data = cri_flow, weights = (inv_weight/1)*112)

tab_model(m30, m30_stock, m30_flow, p.style = "stars", show.ci = F, rm.terms = c("(Intercept)"))
```

###
