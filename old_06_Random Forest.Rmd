---
title: "Random Forest"
output: html_notebook
---

```{r setup}
rm(list = ls())
library(pacman)

pacman::p_load("tidyverse", "randomForest", "caTools", "rpart", "rpart.plot")


```

### Load Data

```{r load, warning=F,message=F}
cri <- read.csv(file = "data/cri.csv", header = T)
cri_str <- read.csv(file = "data/cri_str.csv", header = T)
cri_team <- read.csv(file = "data/cri_team.csv", header = T)
cri_team_combine <- read.csv(file = "data/cri_team_combine.csv", header = T)
```

### Data Prep

```{r rain_prep, warning=F, message=F}

# create categories from aspects of the teams
cri <- cri %>% 
  mutate(stat_cat = ifelse(is.na(stat), NA, ifelse(stat < 0, "Low", ifelse(stat > -0.000000001 & stat < 0.45, "Mid", "High"))),
         belief_cat = ifelse(is.na(belief), NA, ifelse(belief < -0.5, "Low", ifelse(belief > -0.500000001 & belief < 0.12, "Mid", "High"))),
         topic_cat = ifelse(is.na(topic), NA, ifelse(topic < -0.3, "Low", ifelse(topic > -0.300000001 & topic < 0.02, "Mid", "High"))),
         total_score_cat = ifelse(is.na(total_score), NA, ifelse(total_score < 0.35, "Low", ifelse(total_score > 0.34999999 & total_score < 0.515, "Mid", "High"))),
         pro_immigrant_cat = ifelse(is.na(pro_immigrant), NA, ifelse(pro_immigrant < 2.001, "High", ifelse(pro_immigrant < 3.01, "Mid", "Low")))
  )

# drop duplicate teams

# get clean grouping variable (all scale types in one factor)
cri <- cri %>%
  mutate(DVs = ifelse(Scale == 1,"Scale",DV),
         AME_Zt = ifelse(AME_Z > 1, 1, AME_Z),
         AME_Zt = ifelse(AME_Zt < -1, -1, AME_Zt),
         iv_type2 = ifelse(main_IV_type=="Change in Flow","Flow",main_IV_type),
         iv_type2 = as.factor(iv_type2),
         DVn = as.factor(DVs),
         stat_cat_factor = factor(stat_cat, levels = c("Low","Mid","High")),
         belief_cat_factor = factor(belief_cat, levels = c("Low","Mid","High")),
         topic_cat_factor = factor(topic_cat, levels = c("Low","Mid","High")),
         total_score_cat_factor = factor(total_score_cat, levels = c("Low","Mid","High")),
         pro_immigrant_cat_factor = factor(pro_immigrant_cat, levels = c("Low","Mid","High"))
         )



# team level
cri_team_combine <- cri_team_combine %>%
  mutate(AME_Zt = ifelse(AME_Z > 1, 1, AME_Z),
         AME_Zt = ifelse(AME_Zt < -1, -1, AME_Zt),
         iv_type2 = ifelse(Stock == 1, "Stock", "Flow"),
         iv_type2 = as.factor(iv_type2),
         stat_cat = ifelse(stat_cat == "Highest" | stat_cat == "High", "High", ifelse(stat_cat == "Low", "Mid", "Low")), # highest is very rare, combine
         stat_cat_factor = factor(stat_cat, levels = c("Low", "Mid", "High")),
         belief_cat = ifelse(belief_cat == "Highest" | belief_cat == "High", "High", ifelse(belief_cat == "Low", "Mid", "Low")), # high and highest are least frequent, combine
         belief_cat_factor = factor(belief_cat, levels = c("Low", "Mid", "High")),
         topic_cat = ifelse(topic_cat == "Highest" | topic_cat == "High", "High", ifelse(topic_cat == "Lowest", "Low", "Mid")), # highest is least frequent, combine
         topic_cat_factor = factor(topic_cat, levels = c("Low", "Mid", "High")),
         total_score_cat = ifelse(total_score_cat == "Lowest" | total_score_cat == "Low", "Low", ifelse(total_score_cat == "High", "Mid", "High")), # low and lowest are least frequent, combine
         total_score_cat_factor = factor(total_score_cat, levels = c("Low", "Mid", "High")),
         pro_immigrant_cat = ifelse(is.na(pro_immigrant), NA, ifelse(pro_immigrant < 2.001, "High", ifelse(pro_immigrant < 3.01, "Mid", "Low"))),
         pro_immigrant_cat_factor = factor(pro_immigrant_cat, levels = c("Low","Mid","High"))
  )

      


```

### Let's start with a decision tree


```{r dt}
cri_dt <- cri[,c("AME","p","iv_type2","DVn","stat_cat_factor","belief_cat_factor","topic_cat_factor",
                 "total_score_cat_factor","pro_immigrant_cat_factor")]

cri_dt <- cri_dt %>%
  mutate(
    AME_sig05 = case_when(
      AME > 0 & p <= 0.05 ~ 1,
      AME < 0 & p <= 0.05 ~ -1,
      AME = 0 | p > 0.05 ~ 0,
      TRUE ~ NA_real_
    ),
    AME_sig05 = as.factor(AME_sig05)
  )

cri_dt <- cri_dt[,-c(1:2)]
## Split the sample to a train and test set 
set.seed(167)
traintestsplit <- sample.split(Y = cri_dt,SplitRatio = 0.8)

cri_train_set <- cri_dt[traintestsplit,]
cri_test_set <- cri_dt[!traintestsplit,]

## Train the model with Decision Tree
cri_train_set <- cri_train_set[complete.cases(cri_train_set),]

cri_train <- rpart(formula = AME_sig05 ~ ., 
                   data = cri_train_set, method = "class")


png(filename = "results/Decision Tree.png", height = 1200, width = 1600, res = 168)
rpart.plot(cri_train, extra = 104)
dev.off()

knitr::include_graphics( "results/Decision Tree.png")

## Predict

cri_test <- predict(cri_train, cri_test_set, type = "class")

## Confusion matrix

cmatrix <- table(cri_test_set$AME_sig05, cri_test)
cmatrix

## Accuracy = diagonal 

accuracy <- sum(diag(cmatrix))/sum(cmatrix)
accuracy


```


### Try the random forest technique

```{r rf}
cri_rf <- cri_dt


```





