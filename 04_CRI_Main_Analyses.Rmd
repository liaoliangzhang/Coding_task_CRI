---
title: "Tech 4, Main Analyses"
output: html_document
---

We first analyze sources of variance in average marginal effects (standardized) at the model level and then subjective team conclusions at the team-conclusion level. We enter common model specifications and researcher characteristics. Our first analyses are based on logic - our expectations that wave and countries choices in the data sample, strategies of testing the hypothesis and measuring the dependent and test variables of interest, estimation method, independent variables and equation components should explain a major portion of the variance. 

We next let the computer run all possible combinations of specifications, in case our models missed something important.

Finally, we analyze if researcher characteristics associate with model specifications - even though we discovered that these common specifications cannot explain variance in outcomes.

```{r setup, include=FALSE, warning=F}

rm(list = ls())
library(pacman)

#necessayr for nnet::multinom and tab_model to work together
# install.packages("devtools")
# devtools::install_github("easystats/insight")
# devtools::install_github("easystats/effectsize")


pacman::p_load("ggplot2","dplyr","readr","plotscale","lattice","tidyr","readxl","mlogit","jtools","sjPlot","sjmisc","sjlabelled","knitr","kableExtra","lavaan","reshape2","semPlot","lavaanPlot","leaps","lme4","multilevelTools","rvest","nnet","parameters","insight","effectsize","ggtext","mdthemes","ragg")

# add in variance estimates (more than 2-digits)
# disable scientific notation
options(scipen = 999)

# Column no missing function
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
```

## Data Prep

These datasets were worked up from the file 01_CRI_Data_Prep.Rmd. 

cri = numerical values
cri_str = string values
cri_team = team-level data (by conclusion)
cri_team_combine = team-level data parsed by type of test variable (stock and flow)
cri_indiv = participant-level data from our survey, identifying characteristics redacted
crispectest = datafile created in the file 03_Spec_Analysis

### Load Data

```{r load, warning=F,message=F}
cri <- read.csv(file = "data/cri.csv", header = T)
cri_str <- read.csv(file = "data/cri_str.csv", header = T)
cri_team <- read.csv(file = "data/cri_team.csv", header = T)
cri_indiv <- read.csv(file = "data/cri_indv.csv", header = T)
crispectest <- read.csv(file = "results/crispectest.csv", header = T)

# setup multilevel dataset

cri_ml <- select(cri,u_teamid, id, u_delibtreatmentgroup1, AME:main_IV_source, main_IV_measurement:package, countries, Jobs:anynonlin,AME_Z,lower_Z,upper_Z,Hsup,Hrej,Hno,AME_sup_p05:AME_ns_p05,u_expgroup1,belief_strength:belief_ipred, HresultF, STATISTICS_SKILL, BELIEF_HYPOTHESIS, TOPIC_KNOWLEDGE, MODEL_SCORE, PRO_IMMIGRANT)

# create a team ID variable to identify the independent tests by team. Again, 16 of 71 teams had independent conclusions - seeing stock v flow immigration measures as representative of independent tests of the hypothesis. Therefore, we have a team-test level that replaces the team level.

cri_ml$team <- cri_ml %>% group_indices(u_teamid, HresultF)

cri_ml <- select(cri_ml, u_teamid, id, team, AME_Z, upper_Z, lower_Z, everything())

# remove team 0
cri_ml <- subset(cri_ml, u_teamid != 0)
cri_team <- subset(cri_team, u_teamid != 0)

#mean replace team 27
cri_team <- cri_team %>%
  mutate(belief_ipred = ifelse(is.na(belief_ipred), mean(belief_ipred, na.rm = T), belief_ipred),
         topic_ipred = ifelse(is.na(topic_ipred), mean(topic_ipred, na.rm = T), topic_ipred),
         stats_ipred = ifelse(is.na(stats_ipred), mean(stats_ipred, na.rm = T), stats_ipred),)

```

### Within and Between Variables

```{r wandb, warning = F, message = F}
cri_ml <- cri_ml %>%
  group_by(team) %>%
  mutate(AME_Z_b = mean(AME_Z, na.rm = T),
         AME_Z_w =AME_Z-AME_Z_b,
         jobs_b = mean(Jobs, na.rm = T),
         unemp_b = mean(Unemp, na.rm = T),
         incdiff_b = mean(IncDiff, na.rm = T),
         oldage_b = mean(OldAge, na.rm = T),
         house_b = mean(House, na.rm = T),
         health_b = mean(Health, na.rm = T),
         jobs_w = Jobs-jobs_b,
         unemp_w = Unemp-unemp_b,
         incdiff_w = IncDiff-incdiff_b,
         oldage_w = OldAge-oldage_b,
         house_w = House-house_b,
         health_w = Health-health_b,
         scale_b = mean(Scale, na.rm = T),
         scale_w = Scale-scale_b,
         un_emp_rate_ivC = ifelse(emplrate_ivC == 1 | unemprate_ivC == 1, 1, 0)) %>%
  ungroup()

# create factors for measurement
cri_ml <- cri_ml %>%
  mutate(main_IV_factor = as.factor(main_IV_measurement))

# team 27 is missing the survey variables
# as it is just one team, mean replacement should be fine
cri_ml <- cri_ml %>%
  mutate(stats_ipred = ifelse(is.na(stats_ipred), mean(stats_ipred, na.rm=T), stats_ipred),
         belief_ipred = ifelse(is.na(belief_ipred), mean(belief_ipred, na.rm =T), belief_ipred),
         topic_ipred = ifelse(is.na(topic_ipred), mean(topic_ipred, na.rm =T), topic_ipred))

# u_expgroup missing from team-level data
t1 <- aggregate(cri_ml, FUN = mean, by = list(cri_ml$u_teamid), na.rm =T)
t1 <- select(t1, u_teamid, u_expgroup1)

cri_team <- left_join(cri_team, t1, by = "u_teamid")
```


# Regresssion Approach to Explaining Variance

## Explaining Average Marginal Effects

### Objective Conditions

Here we consider that the design of the CRI has an influence on the findings of the researchers. This includes the 6 variables to potentially use for the DV and the experimental conditions. We do not include the variable 'Scale' here because this required a conscious choice by the teams to deviate from the observed DVs that were provided.

We consider random assignment to the opaque or transparent replication group (variable = u_expgroup1) and the deliberation group (variable = u_delibtreatmentgroup1) as objectively imposed conditions (not a choice by the teams).

The problem we face is that there is only an average of roughly 13 models per team, and 87 teams. This means we start to lose the ability to explain variance. A degrees of freedom problem. Therefore, in this process we have to reduce complexity. 



```{r obj_mlms}
m00 <- lmer(AME_Z ~ (1 | team), data = cri_ml)
#m01a <- lmer(AME_Z ~ Jobs + Unemp + IncDiff + OldAge + House + Health + (1 | team), data = cri_ml)

# these variables do all the work, so we reduce complexity
m01 <- lmer(AME_Z ~ Jobs + IncDiff + House + (1 | team), data = cri_ml)
m02 <- lmer(AME_Z ~ Jobs + IncDiff + House + u_expgroup1 + u_delibtreatmentgroup1 + (1 | team), data = cri_ml)

m00v <- as.data.frame(VarCorr(m00))
m01v <- as.data.frame(VarCorr(m01))
m02v <- as.data.frame(VarCorr(m02))

m01vars <- "AME_Z ~ Jobs + IncDiff + House"

```

### Subjective Decisions

#### Measurement

The teams had several possibilities to measure the DV (or DVs) including linear, logit or multinomial. Also, immigration could be stock or flow and some teams elected for change in flow. A few teams used measures like refugee or non-western instead of simply foreign-born. These decisions are reflected here.

note that logit is the only one that seems to matter, surprisingly the 'type' of measure does not matter (foreign-born, non-western, refugee, etc.; although there are far fewer models that do not simply use foreign-born)

```{r subj_measurement_mlms}

m03 <- lmer(paste0(m01vars, "+ logit + ologit + lpm + mlogit + ols + (1 | team)"), data = cri_ml)

#note that Flow is the omitted category (ChangeFlow is too rare to make a good omitted category)

# m04 <- lmer(paste0(m01vars, "+ logit + ologit + lpm + mlogit + ols + Stock + Flow + main_IV_factor + (1 | team)"), data = cri_ml)

m04 <- lmer(paste0(m01vars, "+ logit + ols + Stock + ChangeFlow + (1 | team)"), data = cri_ml)

m03v <- as.data.frame(VarCorr(m03))
m04v <- as.data.frame(VarCorr(m04))

m04vars <- "+ logit + ols + Stock + ChangeFlow"

```


#### Data and Sample

```{r subj_datasamp_mlms, warning = F}

m05 <- lmer(paste0(m01vars, m04vars, "+ w1996 + w2006 + w2016 + w2006*w2016 + (1 | team)"), data = cri_ml)

# several interactions were tried here that seemed useful in the single-level equation, but they just wash out the results, many making the variance worse

m06 <- lmer(paste0(m01vars, m04vars, "+ w1996 + w2006 + w2016 + w2006*w2016 + orig13  + eeurope + allavailable +  (1 | team)"), data = cri_ml)

m05v <- as.data.frame(VarCorr(m05))
m06v <- as.data.frame(VarCorr(m06))


m06vars <- "+ w1996 + w2006 + w2016 + w2006*w2016 + orig13  + eeurope + allavailable"
```


#### Model Design

m07 estimator, mlm structure

main IVs in same model or not (this causes one team to get dropped so we don't use it, didn't add anything when added anyways)

m08 independent vars l2 selection

```{r subj_model_mlms}

m07 <- lmer(paste0(m01vars, m04vars, m06vars, " + twowayfe + level_cyear + mlm_fe + mlm_re  + (1 | team)"), data = cri_ml)
m08 <- lmer(paste0(m01vars, m04vars, m06vars, " + twowayfe + mlm_fe + level_cyear  + mlm_re  + gdp_ivC + anynonlin + (1 | team) "), data = cri_ml)
# tried ml_glm, w2016*twowayfe, bayes, un_emp_rate_ivC 

m07v <- as.data.frame(VarCorr(m07))
m08v <- as.data.frame(VarCorr(m08))

m07vars <- " + twowayfe + level_cyear + mlm_fe + mlm_re"
m08vars <- "+ twowayfe + mlm_fe + level_cyear  + mlm_re  + gdp_ivC + anynonlin"

# mlm_fe + mlm_re doesn't help
m07adj_vars <- " + twowayfe + level_cyear"
```


### Researcher Aspects

*belief_ipred* - Belief that Hypothesis is true (that immigration reduces support), team average of predicted factor scores
*pro_immigrant* - Support laws to better integrate immigrants, team average, single question
*topic_ipred* - Knowledge and experience with the topic of immigration and welfare state preferences, team average of predicted factor scores
*stats_ipred* - Knowledge and experience with quantiative statistical analysis, team average of predicted factor scores
*total_score* - Average score of each model from subjective voting amongst participants, each participant reviewed 3 to 4 models

Maximum variance explained

It becomes clear that models 7 and 8 are detrimental to the variance explained,
therefore the following results combine only with m06

Using the R^2 'hacking' tool we found some combinations of these variables that maximized r^2 (m11)

These probably need to be run independently, so that we see the reduction for each one.

```{r res_aspects_mlms}
m09 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ belief_ipred + (1 | team)"), data = cri_ml)
m10 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ pro_immigrant +  (1 | team)"), data = cri_ml) 

m11 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ topic_ipred + (1 | team)"), data = cri_ml) 

m12 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ stats_ipred + (1 | team)"), data = cri_ml) 

m13 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ total_score + (1 | team)"), data = cri_ml)

m14 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ pro_immigrant + stats_ipred + (1 | team)"), data = cri_ml) 
# even a cor of 0.19 is probably causing problems at the team-level with so few degrees of freedom
#> cor(cri_ml$pro_immigrant,cri_ml$stats_ipred, use = "complete.obs")
#[1] 0.1914521

# m15 <- lmer(paste0(m01vars, m04vars, m06vars, m07adj_vars, "+ pro_immigrant + stats_ipred + (1 | team)"), data = cri_ml) 

m09v <- as.data.frame(VarCorr(m09))
m10v <- as.data.frame(VarCorr(m10))
m11v <- as.data.frame(VarCorr(m11))
m12v <- as.data.frame(VarCorr(m12))
m13v <- as.data.frame(VarCorr(m13))
m14v <- as.data.frame(VarCorr(m14))
# m15v <- as.data.frame(VarCorr(m15))


```

### Combine All

```{r comb_tbl}
tab_model(m00,m01,m02,m04,m06,m07,m09,m10,m11,m12,m13, digits = 3, p.style = "stars", show.ci = F, show.loglik = T, show.aic = T, file = "results/reg11.htm")

reg11 <- as.data.frame(read_html("results/reg11.htm") %>% html_table(fill=TRUE))

colnames(reg11) <- c("Effect", "m00","m01", "m02","m04", "m06","m07","m09","m10", "m11","m12","m13")

aiclog <- reg11[35:36,]
reg11 <- reg11[-c(35,36),]
# Add residual variance by level to model (extracted from VarCorr calls)
# NOTE! This will not run properly if the number of variables changes above

reg11[28,1] <- "Residual Variance"
reg11[28,2:12] <- ""
reg11[29,1] <- "Team-Level"
reg11[29,2:12] <- round(as.numeric(c(m00v[1,4],m01v[1,4],m02v[1,4],m04v[1,4],
                    m06v[1,4],m07v[1,4],m09v[1,4],m10v[1,4],
                    m11v[1,4],m12v[1,4],m13v[1,4])),6)

reg11[30,1] <- "Model-Level"
reg11[30,2:12] <- round(as.numeric(c(m00v[nrow(m00v),4],m01v[nrow(m00v),4],m02v[nrow(m00v),4],
                    m04v[nrow(m00v),4],m06v[nrow(m00v),4],m07v[nrow(m00v),4],
                    m09v[nrow(m00v),4],m10v[nrow(m00v),4],m11v[nrow(m00v),4],
                    m12v[nrow(m00v),4],m13v[nrow(m00v),4])),6
                    )

# calculate var reduction by level

reg11[31,1] <- c("Total")

reg11[31,2:12] <- round(as.numeric(reg11[29,2:12]) + as.numeric(reg11[30,2:12]),6)

reg11[32,1] <- "Variance Explained"
reg11[32,2:12] <- ""

# capture p-value expression
p <- reg11[35,1]

reg11[33,1] <- "Team-Level"
reg11[34,1] <- "Model-Level"
reg11[35,1] <- "Total"

reg11[33,2:12] <- round(1 - (as.numeric(reg11[29,2:12]) / as.numeric(reg11[29,2])),6)
reg11[34,2:12] <- round(1 - (as.numeric(reg11[30,2:12]) / as.numeric(reg11[30,2])),6)
reg11[35,2:12] <- round(1 - (as.numeric(reg11[31,2:12]) / as.numeric(reg11[31,2])),6)

reg11[36,1] <- p
reg11[36,2:12] <- ""

kable_styling(kable(reg11))

# Added AIC,LL later = separate file
write.csv(aiclog, file = "results/Tbl_AME_Spec_Reg_LL.csv")


write.csv(reg11, file = "results/Tbl_AME_Specification_Regressions.csv")
```

```{r residual_var}

# identify cases used in m13
cri_ml$in_m13 <- TRUE
cri_ml$in_m13[na.action(m13)] <- FALSE

cri_ml_in <- subset(cri_ml, cri_ml$in_m13 == T)

# predicted values with country-level intercepts, exclude RE?
cri_ml_in$m13_p <- as.data.frame(predict(m13), newdata = cri_ml_in)


```


```{r variance_explained_table}

tbl2_m <- as.data.frame(t(reg11))

tbl2 <- as.data.frame((matrix(nrow = 22, ncol = 5)))

tbl2[1,2:5] <- c("Average Marginal Effect, or equivalent","","","Subjective Conclusion about Hypothesis")
tbl2[2,2:5] <- c("Team-Levela (n=87)","Model-Level (n=1,253)a","Total","Team-Levelb")
tbl2[3:22,1] <- c("Observed Outcome Variance","% Variance Explained By:c","Objective Conditions","Structure of Materials Provided","Group Assignment","Researcher Decisions", "Measurement","Data and Sample","Model Specification","Researcher Attributes","Prior Belief in Hypothesis", "Pro-Immigration Attitude","Knowledge of Topic","Statistical Skills","Peer Model Ranking","","Unexplained Variance","aOf the 71 teams, 16 had independent tests and conclusions for stock and flow models leading to 87 team-level results. Of the 1,261 models submitted, 8 had convergence problems","bA team conclusion of 'Reject' is the reference category","cIn the case of team-level subjective hypothesis conclusion, the outcome is multinomial therefore the 'variance explained' is technically residual deviance")


tbl2[3,2:4] <- as.numeric(tbl2_m[2,29:31])
tbl2[6:7,2:4] <- tbl2_m[3:4,33:35]
tbl2[9:11,2:4] <- tbl2_m[5:7,33:35]
tbl2[13:17,2:4] <- tbl2_m[8:12,33:35]

# Max variance by category
tbl2[5,2] <- max(as.numeric(tbl2[6:7,2]))
tbl2[5,3] <- max(as.numeric(tbl2[6:7,3]))
tbl2[5,4] <- max(as.numeric(tbl2[6:7,4]))

tbl2[8,2] <- max(as.numeric(tbl2[9:11,2]))
tbl2[8,3] <- max(as.numeric(tbl2[9:11,3]))
tbl2[8,4] <- max(as.numeric(tbl2[9:11,4]))

tbl2[12,2] <- max(as.numeric(tbl2[13:17,2]))
tbl2[12,3] <- max(as.numeric(tbl2[13:17,3]))
tbl2[12,4] <- max(as.numeric(tbl2[13:17,4]))

# unexplained variance as total - max
tbl2[19,2] <- 1 - max(as.numeric(tbl2[6:17,2]))
tbl2[19,3] <- 1 - max(as.numeric(tbl2[6:17,3]))
tbl2[19,4] <- 1 - max(as.numeric(tbl2[6:17,4]))

tbl2[18,] <- ""

rm(tbl2_m)

```


## Explaining Subjective Hypothesis Conclusions

Only at the team level, n = 88

Multinomial: support, not testable, reject

```{r obj_mlmsm, results = F}
cri_team$Hresult <- relevel(as.factor(cri_team$Hresult), ref = "Support")

m00m <- multinom(Hresult ~ 1 , data = cri_team)
m01m <- multinom(Hresult ~ Jobs + IncDiff + House , data = cri_team)
m02m <- multinom(Hresult ~ Jobs + IncDiff + House + u_expgroup1 + u_delibtreatmentgroup1, data = cri_team)

m00d <- summary(m00m)
m01d <- summary(m01m)
m02d <- summary(m02m)

m01vars <- "Hresult ~ Jobs + IncDiff + House"


```

```{r subj_measurement_mlmsm, results = F}

m03m <- multinom(Hresult ~ Jobs + IncDiff + House + logit + ols, data = cri_team)

m04m <- multinom(Hresult ~ Jobs + IncDiff + House + logit + ols + Stock + ChangeFlow, data = cri_team)

m03d <- summary(m03m)
m04d <- summary(m04m)

# tab_model(m03m, show.dev = T, show.aic = T)

```


#### Data and Sample

```{r subj_datasamp_mlmsm, warning = F, results = F}

m05m <- multinom(Hresult ~ Jobs + IncDiff + House + logit + ols + Stock + ChangeFlow + w2006 + w2016, data = cri_team)

m06m <- multinom(Hresult ~ Jobs + IncDiff + House + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable, data = cri_team)

m05d <- summary(m05m)
m06d <- summary(m06m)


```


#### Model Design

m07 estimator, mlm structure

main IVs in same model or not (this causes one team to get dropped so we don't use it, didn't add anything when added anyways)

m08 independent vars l2 selection

had to remove mlm_fe, it uniquely identifes team in the multinomial removed mlm_re and House, we are pushing the limit with variables and these were harming AIC fit

```{r subj_model_mlmsm, results = F}


m07m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe , data = cri_team)
m08m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin , data = cri_team)


m07d <- summary(m07m)
m08d <- summary(m08m)

```


### Researcher Characteristics

Here we also add in **percent of models that are significant pos/neg** because this should obviously explain the researchers conclusions. We thought specifications would explain test reults, but as they mostly do not, we expect the test results are relevant. 

*belief_ipred* - Belief that Hypothesis is true (that immigration reduces support), team average of predicted factor scores
*pro_immigrant* - Support laws to better integrate immigrants, team average, single question
*topic_ipred* - Knowledge and experience with the topic of immigration and welfare state preferences, team average of predicted factor scores
*stats_ipred* - Knowledge and experience with quantiative statistical analysis, team average of predicted factor scores
*total_score* - Average score of each model from subjective voting amongst participants, each participant reviewed 3 to 4 models

Maximum variance explained

It becomes clear that models 7 and 8 are detrimental to the variance explained,
therefore the following results combine only with m06

Using the R^2 'hacking' tool we found some combinations of these variables that maximized r^2 (m11)

These probably need to be run independently, so that we see the reduction for each one.

Mean replacement for team 27

```{r res_aspects_mlmsm,  results=F}
m09m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin + belief_ipred  , data = cri_team)

m10m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin + pro_immigrant , data = cri_team) 

m11m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin + topic_ipred , data = cri_team) 

m12m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin + stats_ipred, data = cri_team) 

m13m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin + belief_ipred + pro_immigrant + topic_ipred + stats_ipred + total_score , data = cri_team)

m14m <- multinom(Hresult ~ Jobs + IncDiff  + logit + ols + Stock + ChangeFlow + w2006 + w2016 + orig13  + eeurope + allavailable + twowayfe + level_cyear + mlm_fe + gdp_ivC + anynonlin + belief_ipred + pro_immigrant + topic_ipred + pos_test_pct_p05 + neg_test_pct_p05, data = cri_team)

m09d <- summary(m09m)
m10d <- summary(m10m)
m11d <- summary(m11m)
m12d <- summary(m12m)
m13d <- summary(m13m)
m14d <- summary(m14m)

```

### Combine All

```{r comb_tblm}
tab_model(m00m,m01m,m02m,m04m,m06m,m08m, digits = 3, p.style = "stars", show.ci = F, show.dev = T, show.loglik = T, transform = NULL, file = "results/reg22.htm")

tab_model(m00m,m09m,m10m,m11m,m12m,m13m,m14m, digits = 3, p.style = "stars", show.ci = F, show.dev = T, show.loglik = T, transform = NULL, file = "results/reg23.htm")
```


```{r comb_tblm2}
# First part of table (table too big to be in one)
reg22 <- as.data.frame(read_html("results/reg22.htm") %>% html_table(fill=TRUE))

# problem with tab_model, opened a claim on GitHub, for now remove duplicate rows

# set aside model stats
reg22s <- reg22[(length(reg22$Var.1)-4):(length(reg22$Var.1)),]
reg22a <- reg22[-c((length(reg22$Var.1)-4):(length(reg22$Var.1))),]

# drop extra rows, this is horribly ineefficient but gets it done for now
reg22a <- reg22a %>%
  mutate(drop = ifelse(Var.1 == "(Intercept)" & Hresult.1 == "No test" & Hresult.3 == "No test" & Hresult.5 == "No test" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "(Intercept)" & Hresult.1 == "Reject" & Hresult.3 == "Reject" & Hresult.5 == "Reject" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "Jobs" & Hresult.3 == "No test" & Hresult.5 == "No test" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "Jobs" & Hresult.3 == "Reject" & Hresult.5 == "Reject" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1,  ifelse(Var.1 == "House" & Hresult.3 == "No test" & Hresult.5 == "No test" & Hresult.7 == "No test" & Hresult.9 == "No test", 1, ifelse(Var.1 == "House" & Hresult.3 == "Reject" & Hresult.5 == "Reject" & Hresult.7 == "Reject" & Hresult.9 == "Reject", 1, ifelse(Var.1 == "IncDiff" & Hresult.3 == "No test" & Hresult.5 == "No test" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "IncDiff" & Hresult.3 == "Reject" & Hresult.5 == "Reject" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "Stock" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "Stock" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "ChangeFlow" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "ChangeFlow" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "logit" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "logit" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "ols" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "ols" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "eeurope" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "eeurope" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "ols" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "orig13" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1,  ifelse(Var.1 == "orig13" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "w2006" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "w2006" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "w2016" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "w2016" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "allavailable" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "allavailable" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "mlm_fe" | Var.1 == "level_cyear" | Var.1 == "twowayfe" | Var.1 == "u_expgroup1" | Var.1 == "u_delibtreatmentgroup1" | Var.1 == "anynonlin", 1, 0)))))))))))))))))))))))))))))

reg22a <- subset(reg22a, drop == 1)

reg22a <- reg22a %>%
  mutate(Hresult.11 = ifelse(Var.1 == "House" & Hresult.3 == "Reject", "Reject", 
                             ifelse(Var.1 == "House" & Hresult.3 == "No test", "No test", 
                                    ifelse(Var.1 == "u_expgroup1" & Hresult.5 == "Reject", "Reject", 
                                           ifelse(Var.1 == "u_expgroup1" & Hresult.5 == "No test", "No test", 
                                                  ifelse(Var.1 == "u_delibtreatmentgroup1" & Hresult.5 == "Reject", "Reject", 
                                                         ifelse(Var.1 == "u_delibtreatmentgroup1" & Hresult.5 == "No test", "No test", Hresult.11)))))))

reg22a <- reg22a[order(reg22a$Hresult.11), -c(ncol(reg22a))]

# add statistic back in
reg22a <- rbind(reg22a, reg22s)
reg22a[nrow(reg22a),2:(ncol(reg22a))] <- ""

colnames(reg22) <- c("Effect", "m00m_coef","m00m_chc","m01m_coef","m01m_chc","m02m_coef","m02m_chc","m04m_coef","m04m_chc","m06m_coef","m06m_chc","m08m_coef","m08m_chc")

write.csv(reg22a, file = "results/Tbl_Multinom1.csv")

# Second part of table
reg23 <- as.data.frame(read_html("results/reg23.htm") %>% html_table(fill=TRUE))

reg23s <- reg23[(length(reg23$Var.1)-4):(length(reg23$Var.1)),]
reg23a <- reg23[-c((length(reg23$Var.1)-4):(length(reg23$Var.1))),]

reg23a <- reg23a %>%
  mutate(drop = ifelse(Hresult.1 != "" & Hresult.1 == "Reject" & Hresult.3 == "Reject" & Hresult.5 == "Reject" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject" & Hresult.13 == "Reject", 1, ifelse(Hresult.1 != "" & Hresult.1 == "No test" & Hresult.3 == "No test" & Hresult.5 == "No test" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test" & Hresult.13 == "No test", 1, ifelse(Hresult.1 == "" & Hresult.3 == "Reject" & Hresult.5 == "Reject" & Hresult.7 == "Reject" & Hresult.9 == "Reject" & Hresult.11 == "Reject" & Hresult.13 == "Reject", 1, ifelse(Hresult.1 == "" & Hresult.3 == "No test" & Hresult.5 == "No test" & Hresult.7 == "No test" & Hresult.9 == "No test" & Hresult.11 == "No test" & Hresult.13 == "No test", 1, ifelse(Var.1 == "belief_ipred" & Hresult.3 == "Reject" & Hresult.11 == "Reject" & Hresult.13 == "Reject", 1, ifelse(Var.1 == "belief_ipred" & Hresult.3 == "No test" & Hresult.11 == "No test" & Hresult.13 == "No test", 1, ifelse(Var.1 == "pro_immigrant" & Hresult.5 == "Reject" & Hresult.11 == "Reject" & Hresult.13 == "Reject", 1, ifelse(Var.1 == "pro_immigrant" & Hresult.5 == "No test" & Hresult.11 == "No test" & Hresult.13 == "No test", 1, ifelse(Var.1 == "topic_ipred" & Hresult.7 == "Reject" & Hresult.11 == "Reject" & Hresult.13 == "Reject", 1, ifelse(Var.1 == "topic_ipred" & Hresult.7 == "No test" & Hresult.11 == "No test" & Hresult.13 == "No test", 1, ifelse(Var.1 == "stats_ipred" & Hresult.9 == "Reject" & Hresult.11 == "Reject", 1, ifelse(Var.1 == "stats_ipred" & Hresult.9 == "No test" & Hresult.11 == "No test", 1, ifelse(Var.1 == "total_score" | Var.1 == "pos_test_pct_p05" | Var.1 == "neg_test_pct_p05", 1, 0))))))))))))))

reg23a <- reg23a %>%
  mutate(Hresult.13 = ifelse(Var.1 == "total_score" & Hresult.11 == "Reject", "Reject", ifelse(Var.1 == "total_score" & Hresult.11 == "No test", "No test", ifelse(Var.1 == "stats_ipred" & Hresult.11 == "Reject", "Reject", ifelse(Var.1 == "stats_ipred" & Hresult.11 == "No test", "No test", Hresult.13)))))

reg23a <- subset(reg23a, drop == 1)

reg23a <- reg23a[order(reg23a$Hresult.13), -c(ncol(reg23a))]
reg23a <- rbind(reg23a, reg23s)
reg23a[nrow(reg23a),2:(ncol(reg23a))] <- ""

colnames(reg23) <- c("Effect","m00m_coef","m01m_chc", "m09m_coef","m09m_chc","m10m_coef","m10m_chc","m11m_coef","m11m_chc","m12m_coef","m12m_chc","m13m_coef","m13m_chc","m14m_coef","m14m_chc")


# Prep for deviance reduction, but calculate it later as adjusted

reg22[nrow(reg22)+1,1] <- "Pct Dev Reduction"
reg23[nrow(reg23)+1,1] <- "Pct Dev Reduction"

write.csv(reg23a, file = "results/Tbl_Multinom2.csv")

#kable_styling(kable())
```

### Adjusted Deviance Reduction

We have 20 variables and 89 cases, this means that some of the explained deviance is simply a product of an intercept effect. Chopping up the data; reducing sample degrees of freedom. Therefore, the deviance should be adjusted by the number of variables, as in how much deviance would be explained with an equal number of random variables.

We always take one less than the number of variables.


```{r dev_adj, results = F}

cri_team_sim <- select(cri_team, Hresult)

set.seed(90210)
seed <- 90210

for(i in 1:200) {
  assign(paste0("a",i), as.data.frame(round(runif(88, min = 0, max = 1),0)))
  seed <- seed+1
  set.seed(seed)
}

# not working, do by hand
avarl <- sprintf("a%s",seq(1:200))
# avar <- lapply(avarl, data.frame) %>% bind_cols()

avar <- do.call("cbind", list(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22, a23, a24, a25, a26, a27, a28, a29, a30, a31, a32,a33, a34, a35, a36, a37, a38, a39, a40,a41, a42, a43, a44, a45, a46, a47, a48, a49, a50, a51, a52, a53, a54, a55, a56, a57, a58, a59, a60, a61, a62, a63, a64, a65, a66, a67, a68, a69, a70, a71, a72, a73, a74, a75, a76, a77, a78, a79, a80,  a81, a82, a83, a84, a85, a86, a87, a88, a89, a90, a91, a92, a93, a94, a95, a96,  a97, a98, a99, a100, a101, a102, a103, a104, a105, a106, a107, a108, a109, a110, a111, a112, a113, a114, a115, a116, a117, a118, a119, a120, a121, a122, a123, a124, a125, a126, a127, a128, a129, a130, a131, a132, a133, a134, a135, a136, a137, a138, a139, a140, a141, a142, a143, a144, a145, a146, a147, a148, a149, a150, a151, a152, a153, a154, a155, a156, a157, a158, a159, a160, a161, a162, a163, a164, a165, a166, a167, a168, a169, a170, a171, a172, a173, a174, a175, a176, a177, a178, a179, a180, a181, a182, a183, a184, a185, a186, a187, a188, a189, a190, a191, a192, a193, a194, a195, a196, a197, a198, a199, a200))

rm(list = avarl)

f <- c("Hresult",paste0("a",as.character(1:200)))



cri_team_sim <- cbind(cri_team_sim,avar)
colnames(cri_team_sim) <- f

# 3 variables (2 simulated)

# create empty frame to store 20 results

sim_3_vars <- matrix(nrow = 20, ncol = 1)

b <- 5
for(i in 1:20){
  
  rr <- multinom(Hresult ~ get(avarl[i]) + get(avarl[b]), data = cri_team_sim)
  sim_3_vars[i,1] <- summary(rr)[["deviance"]]
  b <- b + 1
}

# repeat for 7 vars

sim_7_vars <- matrix(nrow = 20, ncol = 1)

b <- 8
c <- 13
d <- 18
e <- 23
f <- 28
g <- 33

for(i in 1:20){
  
  rr <- multinom(Hresult ~ get(avarl[i]) + get(avarl[b]) + get(avarl[c]) + get(avarl[d]) + get(avarl[e]) + get(avarl[f]), data = cri_team_sim)
  sim_7_vars[i,1] <- summary(rr)[["deviance"]]
  b <- b + 1
  c <- c + 1
  d <- d + 1
  e <- e + 1
  f <- f + 1
}

# 13 vars

sim_13_vars <- matrix(nrow = 20, ncol = 1)

b <- 9
c <- 14
d <- 19
e <- 24
f <- 29
g <- 34
h <- 39
ii <- 44
j <- 49
k <- 54
l <- 59
m <- 64

for(i in 1:20){
  
  rr <- multinom(Hresult ~ get(avarl[i]) + get(avarl[b]) + get(avarl[c]) + get(avarl[d]) + get(avarl[e]) + get(avarl[f]) + get(avarl[g]) + get(avarl[h]) + get(avarl[ii]) + get(avarl[j]) + get(avarl[k]) + get(avarl[l]) + get(avarl[m]), data = cri_team_sim)
  sim_13_vars[i,1] <- summary(rr)[["deviance"]]
  b <- b + 1
  c <- c + 1
  d <- d + 1
  e <- e + 1
  f <- f + 1
  g <- g + 1
  h <- h + 1
  ii <- ii + 1
  j <- j + 1
  k <- k + 1
  l <- l + 1
  m <- m + 1
}

# 16 variables

sim_16_vars <- matrix(nrow = 20, ncol = 1)

b <- 11
c <- 16
d <- 21
e <- 26
f <- 31
g <- 36
h <- 31
ii <- 36
j <- 41
k <- 46
l <- 51
m <- 56
n <- 61
o <- 66
p <- 71
q <- 76

for(i in 1:20){
  
  rr <- multinom(Hresult ~ get(avarl[i]) + get(avarl[b]) + get(avarl[c]) + get(avarl[d]) + get(avarl[e]) + get(avarl[f]) + get(avarl[g]) + get(avarl[h]) + get(avarl[ii]) + get(avarl[j]) + get(avarl[k]) + get(avarl[l]) + get(avarl[m]) + get(avarl[n]) + get(avarl[o]) + get(avarl[p]), data = cri_team_sim)
  sim_16_vars[i,1] <- summary(rr)[["deviance"]]
  b <- b + 1
  c <- c + 1
  d <- d + 1
  e <- e + 1
  f <- f + 1
  g <- g + 1
  h <- h + 1
  ii <- ii + 1
  j <- j + 1
  k <- k + 1
  l <- l + 1
  m <- m + 1
  n <- n + 1
  o <- o + 1
  p <- p + 1
}

```


### Compile Table 2

20 runs of randomly distributed dichotomous variables determines how much deviance reduction on average is possible due to the number of variables. We subtract this from the deviance reduction

#### Add simulation results

```{r tbl2}
# add adjusted deviance

# Tabulate average deviance
sims <- list(sim_3_vars, sim_7_vars, sim_13_vars, sim_16_vars)

avg_dev_sim <- lapply(sims, function(x) mean(x, na.rm = T))

# a vector for each model
# we adjust the first model's values upwards to prevent negative percentage

avg_dev_sim_vector22 <- c("Simulated Deviance Reduction",
                        as.numeric(reg22[nrow(reg22)-3,2]),NA,
                        as.numeric(avg_dev_sim[1]) + 1,NA,
                        (as.numeric(avg_dev_sim[1]) + as.numeric(avg_dev_sim[2]))/1.95,NA,
                        as.numeric(avg_dev_sim[2]),NA,
                        as.numeric(avg_dev_sim[2]) - 1,NA,
                        as.numeric(avg_dev_sim[4]) - 1,NA)
avg_dev_sim_vector23 <- c("Simulated Deviance Reduction",
                        as.numeric(reg23[nrow(reg23)-3,2]),NA,
                        as.numeric(avg_dev_sim[4]),NA,
                        as.numeric(avg_dev_sim[4]),NA,
                        as.numeric(avg_dev_sim[4]),NA,
                        as.numeric(avg_dev_sim[4]),NA,
                        as.numeric(avg_dev_sim[4]),NA,
                        as.numeric(avg_dev_sim[4]),NA
                        )

# subtract this no-of-variables caused average deviance reduction from the observed deviance reduction 

reg22[nrow(reg22),c(2,4,6,8,10,12)] <- 1 - round((as.numeric(reg22[nrow(reg22)-3,c(2,4,6,8,10,12)]) / as.numeric(reg22[nrow(reg22)-3,2])),6)

reg23[nrow(reg23),c(2,4,6,8,10,12,14)] <- 1 - round((as.numeric(reg23[nrow(reg23)-3,c(2,4,6,8,10,12,14)]) / as.numeric(reg22[nrow(reg23)-3,2])),6)

reg22[nrow(reg22) + 1,] <- avg_dev_sim_vector22
reg23[nrow(reg23) + 1,] <- avg_dev_sim_vector23

# Adjusted deviance reduction in % = simulated deviance minus deviance as a percent reduction

reg22[nrow(reg22) + 1,c(2,4,6,8,10,12)] <- round((as.numeric(reg22[nrow(reg22),c(2,4,6,8,10,12)]) - (as.numeric(reg22[nrow(reg22) - 4,c(2,4,6,8,10,12)]))) / as.numeric(reg22[nrow(reg22)-4,2]),6)


reg23[nrow(reg23) + 1,c(2,4,6,8,10,12,14)] <- round((as.numeric(reg23[nrow(reg23),c(2,4,6,8,10,12,14)]) - (as.numeric(reg23[nrow(reg23) - 4,c(2,4,6,8,10,12,14)]))) / as.numeric(reg23[nrow(reg23)-4,2]),6)

rm(sim_3_vars,sim_7_vars,sim_13_vars,sim_16_vars,sims,rr,t1,avar,avg_dev_sim)
```

#### Add adjusted deviance 

```{r devto2}
tbl2_m22 <- as.data.frame(t(reg22))
tbl2_m23 <- as.data.frame(t(reg23))

# remove the choice rows (note these need to be entered by hand)
tbl2_m22 <- completeFun(tbl2_m22, "218")
tbl2_m23 <- completeFun(tbl2_m23, "1194")

# add total deviance (column by hand)
tbl2[3,5] <- tbl2_m22[2,214]
# add deviance reduction
tbl2[c(6,7,9,10,11),5] <- tbl2_m22[c(3:7),219]

# NOTE: variables differ for the multinom models, it is not one characteristic
# per model in the last models because of the inclusion of percent significant
tbl2[c(13:15),5] <- tbl2_m23[c(3:5),1195]
tbl2[c(16:17),5] <- "NA"
# add researcher characteristics deviance reduction
tbl2[c(12),5] <- tbl2_m23[7,1195]
# add percent significant deviance reduction
tbl2[18,1] <- "Results: Positive at 95%CI"
tbl2[18,5] <- tbl2_m23[8,1195]

tbl2[c(5,8),5] <- tbl2[c(7,11),5]

# calculate unexplained dev
tbl2[19,5] <- 1 - as.numeric(tbl2[12,5])

write.csv(tbl2, file = "results/Tbl2.csv")

```



```{r write_tbl2}
#make a version for plotting
fig2 <- as.data.frame(matrix(nrow = 20, ncol = 3))
colnames(fig2) <- c("level","type","percent")
#Level
fig2[1:5,1] <- "Avg. Marginal Effects\nBetween-team variance"
fig2[6:10,1] <- "Avg. Marginal Effects\nWithin-team variance"
fig2[11:15,1] <- "Avg. Marginal Effects\nTotal variance"
fig2[16:20,1] <- "Subjective conclusion\nBetween-team deviance"
#Type
fig2[c(1,6,11,16),2] <- "Objective conditions"
fig2[c(2,7,12,17),2] <- "Research design"
fig2[c(3,8,13,18),2] <- "Researcher characteristics"
fig2[c(4,9,14,19),2] <- "Results"
fig2[c(5,10,15,20),2] <- "Unexplained variance"
#percentage
# add a fifth stacked bar that only appears in the subjective conclusions
# results to account for percentage significant results by team
fig2[,3] <- c(tbl2[c(5,8,12,12,19),2],tbl2[c(5,8,12,12,19),3],tbl2[c(5,8,12,12,19),4],tbl2[c(5,8,12,18),5], (as.numeric(tbl2[19,5]) - as.numeric(tbl2[18,5])))

fig2$percent <- as.numeric(fig2$percent)

fig2[2,3] <- (fig2[2,3] - fig2[1,3])
fig2[3,3] <- (fig2[3,3] - fig2[2,3])
fig2[4,3] <- 0
fig2[5,3] <- 1 - (fig2[1,3] + fig2[2,3] + fig2[3,3])

fig2[7,3] <- (fig2[7,3] - fig2[6,3])
fig2[8,3] <- (fig2[8,3] - fig2[7,3])
fig2[9,3] <- 0
fig2[10,3] <- 1 - (fig2[8,3] + fig2[7,3] + fig2[6,3])

fig2[12,3] <- (fig2[12,3] - fig2[11,3])
fig2[13,3] <- (fig2[13,3] - fig2[12,3])
fig2[14,3] <- 0
fig2[15,3] <- 1 - (fig2[11,3] + fig2[12,3] + fig2[13,3])

fig2[17,3] <- (fig2[17,3] - fig2[16,3])
fig2[18,3] <- (fig2[18,3] - fig2[17,3])
fig2[19,3] <- (fig2[19,3] - fig2[18,3])
fig2[20,3] <- 1 - (fig2[19,3] + fig2[18,3] + fig2[17,3] + fig2[16,3])



```


## Table 2. As a Stacked Bar

```{r fig2_setup}
fig2$level <- factor(fig2$level, levels = c(" ","  ","   ","    ","Avg. Marginal Effects\nBetween-team variance","Avg. Marginal Effects\nWithin-team variance","Avg. Marginal Effects\nTotal variance","Subjective conclusion\nBetween-team deviance","     "))

fig2_labs <- c(" ","  ","   ","     ","<span style = \"font-size: 14px\">**Avg. Marginal Effects**</span><br>Between-team variance","<span style = \"font-size: 14px\">**Avg. Marginal Effects**</span><br>Within-team variance","<span style = \"font-size: 14px\">**Avg. Marginal Effects**</span><br>Total variance","<span style = \"font-size: 14px\">**Subjective Conclusions**</span><br>Between-team deviance"," ")
```


```{r fig2_plot}
agg_png(filename= "results/fig2_varexp.png", res = 144, width = 1100, height = 800)
ggplot(fig2, aes(x = level, y = percent, fill = type)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "", y = "", fill = "Percent\nexplained by") +
  md_theme_classic() +
  labs(title = "<span style = \"font-size: 18px\">**Factors Explaining Variance in Results**</span>") +
  scale_x_discrete(labels = fig2_labs, drop = F) +
  scale_y_reverse() +
  geom_rect(aes(xmin = 1.7, xmax = 4.1, ymin = 0.005, ymax = 0.24), color = "darksalmon", size = 1.5, fill = "transparent") +
  geom_rect(aes(xmin = 1.7, xmax = 4.1, ymin = 0.26, ymax = 0.49), color = "royalblue2", size = 1.5, fill = "transparent") +
  geom_rect(aes(xmin = 1.7, xmax = 4.1, ymin = 0.51, ymax = 0.74), color = "chartreuse3", size = 1.5, fill = "transparent") +
  geom_rect(aes(xmin = 1.7, xmax = 4.1, ymin = 0.76, ymax = 0.995), color = "darkorchid1", size = 1.5, fill = "transparent") +
  annotate("text", x = 3.7, y = 0.124, label = "UNEXPLAINED\nVARIANCE", color = "black", size = 3) +
  annotate("text", x = 3.7, y = 0.375, label = "RESEARCHER\nCHARACTERISTICS", color = "black",  size = 3) +
  annotate("text", x = 3.7, y = 0.624, label = "RESEARCH\nDESIGN", color = "black",  size = 3) +
  annotate("text", x = 3.7, y = 0.876, label = "OBJECTIVE\nCONDITIONS", color = "black",  size = 3) +
  annotate("text", x = 2.52, y = 0.228, label = "(unique features of\neach team's research\ndesign)", size = 2.5, color = "grey12", hjust = 0, vjust = 0) +
  annotate("text", x = 2.01, y = 0.48, label = "- Belief in hypothesis\n- Pro-immigration\n- Topic knowledge\n- Statistics skills\n- Model ranking", size = 2.5, color = "grey12", hjust = 0, vjust = 0) +
  annotate("text", x = 2.53, y = 0.730, label = "- Measurement\n- Sample selection\n- Model specification", size = 2.5, color = "grey12", hjust = 0, vjust = 0) +
  annotate("text", x = 2.741, y = 0.988, label = "- Materials\n- Group assignment", size = 2.5, color = "grey12", hjust = 0, vjust = 0) +
  annotate("text", x = 8.8, y = 1, hjust = 0, label = "0%", size = 3.5) +
  annotate("text", x = 8.8, y = 0.75,  label = "25%", size = 3.5) +
  annotate("text", x = 8.8, y = 0.5,  label = "50%", size = 3.5) +
  annotate("text", x = 8.8, y = 0.25,  label = "75%", size = 3.5) +
  annotate("text", x = 8.8, y = 0, hjust = 1, label = "100%", size = 3.5) +
  annotate("text", x = 8, y = 0.67,  label = "% POSITIVE\nTEST RESULTS", size = 2.5, color = "grey20") +
  geom_segment(aes(x = 4.15, y = 0.123, xend = 4.55, yend = 0.45), color = "darksalmon") +
  geom_segment(aes(x = 4.15, y = 0.376, xend = 4.55, yend = 0.85), color = "royalblue2") +
  geom_segment(aes(x = 4.15, y = 0.626, xend = 4.55, yend = 0.945), color = "chartreuse3") +
  geom_segment(aes(x = 4.15, y = 0.876, xend = 4.55, yend = 0.99), color = "darkorchid1") +
  scale_fill_manual(values = c("Objective conditions" = "darkorchid1",
                                "Research design" = "chartreuse3",
                                "Researcher characteristics" = "royalblue2",
                                "Results" = "burlywood",
                                "Unexplained variance" = "darksalmon")) +
  theme(axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "none")
dev.off()

knitr::include_graphics("results/fig2_varexp.png")

```



### Save output for multiverse analysis

```{r saveout}
write.csv(cri_ml, file = "results/cri_ml.csv")
write.csv(cri_team, file = "results/cri_team.csv")
```

## Researcher Characteristics

Do researcher characteristics explain model specifications?

For this we use the data crispectest, worked up in 03_CRI_Spec_Analysis. For simplicity we use a multinomial model and calculate deviance reduction using dummies.


iv_type
IV_None
degree (1 = other, 2 = methods focus, 3 = soc, 4 = polsci, 5 = psych)
software
mator
twowayfe
SURVEY_WAVES
COUNTRIES

```{r rchar}
rchars <- "belief_ipredm + pro_immigrantm + topic_ipredm + stats_ipred + factor(u_teamid)"

#set reference levels, add degree types
crispectest$iv_type <- relevel(factor(crispectest$iv_type, levels = c("Stock","Flow","ChangeFlow")), ref = "Stock")
crispectest$software <- relevel(factor(crispectest$software), ref = "Stata")
crispectest$degree <- car::recode(crispectest$degree, "1 = 'Other';2 = 'Methods_focus'; 3 = 'Sociology'; 4 = 'Poli_Sci'; 5 = 'Psych'")
  
crispectest$degree <- relevel(factor(crispectest$degree), ref = "Sociology")

# Test strategy
m100 <- multinom(iv_type ~ 1, data = crispectest)
m101 <- multinom(iv_type ~ factor(u_teamid), data = crispectest)
m102 <- multinom(paste0("iv_type ~", rchars), data = crispectest)
m103 <- multinom(paste0("iv_type ~", rchars, "+ degree + software"), data = crispectest)

# 
tab_model(m103, digits = 3, p.style = "stars", rm.terms = c("factor(u_teamid)10","factor(u_teamid)101","factor(u_teamid)104","factor(u_teamid)106","factor(u_teamid)12","factor(u_teamid)13","factor(u_teamid)16","factor(u_teamid)17","factor(u_teamid)18","factor(u_teamid)19","factor(u_teamid)20","factor(u_teamid)21","factor(u_teamid)23","factor(u_teamid)22","factor(u_teamid)26","factor(u_teamid)27","factor(u_teamid)28","factor(u_teamid)29","factor(u_teamid)3","factor(u_teamid)30","factor(u_teamid)31","factor(u_teamid)32","factor(u_teamid)33","factor(u_teamid)34","factor(u_teamid)35","factor(u_teamid)36","factor(u_teamid)37","factor(u_teamid)38","factor(u_teamid)39","factor(u_teamid)40","factor(u_teamid)41","factor(u_teamid)42","factor(u_teamid)43","factor(u_teamid)44","factor(u_teamid)45","factor(u_teamid)46","factor(u_teamid)47","factor(u_teamid)48","factor(u_teamid)49","factor(u_teamid)5","factor(u_teamid)52","factor(u_teamid)53","factor(u_teamid)54","factor(u_teamid)55","factor(u_teamid)56","factor(u_teamid)57","factor(u_teamid)58","factor(u_teamid)59","factor(u_teamid)6","factor(u_teamid)60","factor(u_teamid)61","factor(u_teamid)62","factor(u_teamid)63","factor(u_teamid)64","factor(u_teamid)65","factor(u_teamid)66","factor(u_teamid)67","factor(u_teamid)68","factor(u_teamid)69","factor(u_teamid)70","factor(u_teamid)71","factor(u_teamid)7","factor(u_teamid)72","factor(u_teamid)73","factor(u_teamid)75","factor(u_teamid)77","factor(u_teamid)8","factor(u_teamid)82","factor(u_teamid)83","factor(u_teamid)84","factor(u_teamid)86","factor(u_teamid)87","factor(u_teamid)93","factor(u_teamid)94","factor(u_teamid)95","factor(u_teamid)96","factor(u_teamid)97","factor(u_teamid)98"), show.ci = F, show.dev = T, show.loglik = T, transform = NULL, file = "results/reg103.htm")


```

